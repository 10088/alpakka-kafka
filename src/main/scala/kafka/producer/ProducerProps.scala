package kafka.producer

import java.util.Properties
import kafka.message.DefaultCompressionCodec
import kafka.message.NoCompressionCodec
import java.util.UUID
import kafka.message.SnappyCompressionCodec

object ProducerProps {

  def apply(brokerList: String, topic: String, clientId: String = UUID.randomUUID().toString): ProducerProps = {
    val props = new Properties()
    props.put("metadata.broker.list", brokerList)

    // defaults
    props.put("compression.codec", DefaultCompressionCodec.codec.toString)
    props.put("client.id", clientId)
    props.put("message.send.max.retries", 3.toString)
    props.put("request.required.acks", -1.toString)
    props.put("producer.type", "sync")

    new ProducerProps(props, topic, clientId)
  }
}

class ProducerProps(private val props: Properties, val topic: String, val clientId: String) {

  def brokerList(brokerList: String): ProducerProps = {
    props.put("metadata.broker.list", brokerList)
    this
  }

  /**
   * Asynchronous Mode
   * The number of messages to send in one batch when using async mode.
   * The producer will wait until either this number of messages are ready
   * to send or bufferMaxMs timeout is reached.
   */
  def asynchronous(batchSize: Int = 200, bufferMaxMs: Int = 500): ProducerProps = {
    props.put("producer.type", "async")
    props.put("batch.num.messages", batchSize.toString)
    props.put("queue.buffering.max.ms", bufferMaxMs.toString)
    this
  }

  /**
   * No Compression
   * Allows you to turn off the compression codec for all data generated by this producer.
   */
  def noCompression(): ProducerProps = {
    props.put("compression.codec", NoCompressionCodec.codec.toString)
    this
  }

  /**
   * Use Snappy Compression instead of the default compression
   */
  def useSnappyCompression(): ProducerProps = {
    props.put("compression.codec", SnappyCompressionCodec.codec.toString)
    this
  }

  /**
   * messageSendMaxRetries
   * This property will cause the producer to automatically retry a failed send request.
   * This property specifies the number of retries when such failures occur. Note that
   * setting a non-zero value here can lead to duplicates in the case of network errors
   * that cause a message to be sent but the acknowledgement to be lost.
   */
  def messageSendMaxRetries(num: Int): ProducerProps = {
    props.put("message.send.max.retries", num.toString)
    this
  }

  /**
   * requestRequiredAcks
   *  0) which means that the producer never waits for an acknowledgement from the broker (the same behavior as 0.7).
   *     This option provides the lowest latency but the weakest durability guarantees (some data will be lost when a server fails).
   *  1) which means that the producer gets an acknowledgement after the leader replica has received the data. This option provides
   *     better durability as the client waits until the server acknowledges the request as successful (only messages that were
   *     written to the now-dead leader but not yet replicated will be lost).
   * -1) which means that the producer gets an acknowledgement after all in-sync replicas have received the data. This option
   *     provides the best durability, we guarantee that no messages will be lost as long as at least one in sync replica remains.
   */
  def requestRequiredAcks(value: Int): ProducerProps = {
    props.put("request.required.acks", value.toString)
    this
  }

  /**
   * Set any additional properties needed
   */
  def setProperties(values: (String, String)*): ProducerProps = {
    values.map { case (key, value) => props.put(key, value) }
    this
  }

  def toProducerConfig: ProducerConfig = new ProducerConfig(props)

}